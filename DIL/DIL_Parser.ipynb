{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     def get_first_trans_defs(self):\n",
    "#         try:\n",
    "#             first_trans = self.soup.find_all(class_=\"trans\")[0]\n",
    "#             first_trans_soup = BeautifulSoup(str(first_trans))\n",
    "#             for d in first_trans_soup.find_all(class_=\"def\"):\n",
    "#                 self.first_trans_defs += d.text.split(', ')\n",
    "#                 self.first_trans_defs = [re.sub(r\"[;:`,\\(?\\)\\[\\]\\n]+\", \"\", d) for d in self.first_trans_defs]\n",
    "#                 self.first_trans_defs = [d.lower().strip() for d in self.first_trans_defs]\n",
    "#         except IndexError:\n",
    "#             pass\n",
    "#         return self.first_trans_defs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Entry():\n",
    "\n",
    "    headword = '<h3.*?>((\\?|\\d)\\s)*(.*?)</h3>'\n",
    "    formae = 'Forms:\\s*(.*?)</p>'\n",
    "    link = 'see.*?href=\\\".*?\\\">((\\?|\\d)\\s)*(.*?)</a>'\n",
    "    alph = 'abcdefghijklmnopqrstuvwxyzáóúíéṡḟōäïāūæēṅǽüöβīḯ'\n",
    "    bad_forms = [\"n\", \"m\", \"f\", \"a\", \"in\", \"is\", \"na\", \"con\", \"co\", \"ra\", \"ar\", \"ol\", \"bar\", \"for\", \"far\", \"an\", \"ro\", \"i\"]\n",
    "    punctuation = \" ?!,.:;†*—/\\-%'$~1234567890̆ \"\n",
    "    prefixes = ['co', 'con', 'for', 'do', 'at', 'as', 'ad', 'ní', 'ro', 'ra', 'a', 'ar', 'ath', 'aith',\n",
    "                'd', 'da', 'dan', 'der', 'derb', 'di', 'dob', 'dom', 'don', 'dot', 'é', 'fo', 'id', 'in',\n",
    "                'ind', 'imm', 'm', 'mí', 'n', 'nd', 'no', 'prím', 's', 't', 'to']\n",
    "\n",
    "\n",
    "    def __init__(self, file):\n",
    "        self.text = file.read()\n",
    "        self.soup = BeautifulSoup(self.text)\n",
    "        self.forms = []\n",
    "        self.defs = []\n",
    "        self.trans = []\n",
    "        self.first_trans = []\n",
    "        self.filtered_defs = []\n",
    "        self.first_trans_defs = []\n",
    "        self.lemma = ''\n",
    "        self.border = ''\n",
    "        self.stem = ''\n",
    "        \n",
    "        \n",
    "    def get_header(self):\n",
    "        if re.search(self.headword, self.text):\n",
    "            self.header = re.search(self.headword, self.text).group(3)\n",
    "        else:\n",
    "            self.header = \"\"\n",
    "        return self.header\n",
    "        \n",
    "    def get_trans(self):\n",
    "        for d in self.soup.find_all(class_=\"trans\"):\n",
    "            self.trans.append(d.text.replace(\"\\n\", \"\"))\n",
    "            self.trans = [re.sub(r\"[:`]\", \"\", t) for t in self.trans]\n",
    "            self.trans = [t.lower().strip(\", \\n:;.\") for t in self.trans]\n",
    "        return self.trans\n",
    "    \n",
    "    \n",
    "    def get_first_trans(self):\n",
    "        try:\n",
    "            self.first_trans = self.trans[0].split(',')\n",
    "            self.first_trans = [re.sub(r\"[;:`,\\(?\\)\\[\\]\\n]+\", \"\", d) for d in self.first_trans]\n",
    "            self.first_trans = [d.lower().strip() for d in self.first_trans]\n",
    "        except IndexError:\n",
    "            pass\n",
    "        return self.first_trans\n",
    "    \n",
    "            \n",
    "    def get_defs(self):\n",
    "        for d in self.soup.find_all(class_=\"def\"):\n",
    "            self.defs += d.text.split(', ')\n",
    "            self.defs = [re.sub(r\"[;:`,\\(?\\)\\[\\]\\n]+\", \"\", d) for d in self.defs]\n",
    "            self.defs = [d.lower().strip() for d in self.defs]\n",
    "        return self.defs\n",
    "    \n",
    "    def intersect_defs_trans(self):\n",
    "        self.filtered_defs = list(set(self.first_trans) & set(self.defs))\n",
    "        return self.filtered_defs\n",
    "    \n",
    "    \n",
    "    def get_first_trans_defs(self):\n",
    "        try:\n",
    "            first_trans = self.soup.find_all(class_=\"trans\")[0]\n",
    "            first_trans_soup = BeautifulSoup(str(first_trans))\n",
    "            for d in first_trans_soup.find_all(class_=\"def\"):\n",
    "                self.first_trans_defs += d.text.split(', ')\n",
    "                self.first_trans_defs = [re.sub(r\"[;:`,\\(?\\)\\[\\]\\n]+\", \"\", d) for d in self.first_trans_defs]\n",
    "                self.first_trans_defs = [d.lower().strip() for d in self.first_trans_defs]\n",
    "                self.first_trans_defs = list(set(self.first_trans_defs))\n",
    "        except IndexError:\n",
    "            pass\n",
    "        return self.first_trans_defs\n",
    "        \n",
    "\n",
    "    def get_forms(self):\n",
    "        res_headword = re.search(self.headword, self.text)\n",
    "        res_forms = re.search(self.formae, self.text)\n",
    "        res_link = re.search(self.link, self.text)\n",
    "        if res_headword:\n",
    "            if res_forms:\n",
    "                self.forms, self.lemma = self.process_forms(res_forms.group(1), res_headword.group(3))\n",
    "            elif res_link and '(' not in res_link.group(3):\n",
    "                self.forms, self.lemma = self.process_forms(res_headword.group(3), res_link.group(3))\n",
    "            else:\n",
    "                self.forms, self.lemma = self.process_forms(res_headword.group(3), res_headword.group(3))\n",
    "        return self.forms, self.lemma\n",
    "\n",
    "\n",
    "    def process_forms(self, forms, lemma):\n",
    "        \"\"\"\n",
    "        :param forms: string with forms\n",
    "        :param lemma: string with lemmas\n",
    "        \"\"\"\n",
    "        self.lemma = lemma.split(\",\")[0].strip(self.punctuation)\n",
    "        if '(?) ' in self.lemma:\n",
    "            self.lemma = self.lemma[self.lemma.index(\" \")+1:]\n",
    "        if self.lemma not in self.prefixes:\n",
    "            self.forms = forms.split(\",\") + lemma.split(\",\")\n",
    "            self.forms = [form.strip(\"1234567890?†* \") for form in self.forms]\n",
    "            self.forms = self.remove_junk()\n",
    "            self.forms = [form for form in self.forms if len(form) != 0]\n",
    "            for form in self.forms:\n",
    "                form = self.check_brackets(form)\n",
    "            self.border = self.find_border()\n",
    "            self.stem = self.find_stem()\n",
    "            for form in self.forms:\n",
    "                self.normalize(form)\n",
    "            self.forms = [form for form in self.forms if len(form) > 0 and form[0] != \"-\"]\n",
    "            self.forms = [form.strip(self.punctuation) for form in self.forms]\n",
    "        else:\n",
    "            pass\n",
    "        return self.forms, self.lemma\n",
    "\n",
    "    def remove_junk(self):\n",
    "            \"\"\"\n",
    "            :return: a list of forms without junk like zero-length forms and hardly restorable\n",
    "            variations in the middle of the form (\"-rrt(h)-\" etc.)\n",
    "            \"\"\"\n",
    "            for form in self.forms:\n",
    "                if len(form) != 0:\n",
    "                    if len(form) == 1 and form in self.punctuation:\n",
    "                        self.forms.pop(self.forms.index(form))\n",
    "                    elif form[0] == \"-\" and form[-1] == \"-\":\n",
    "                        self.forms.pop(self.forms.index(form))\n",
    "                    elif form[-1] == \".\" and len(form) <= 3:\n",
    "                        self.forms.pop(self.forms.index(form))\n",
    "                    elif form in self.bad_forms:\n",
    "                        self.forms.pop(self.forms.index(form))\n",
    "                    elif form[0] == '(' and form[-1] == ')':\n",
    "                        self.forms.pop(self.forms.index(form))\n",
    "                else:\n",
    "                    self.forms.pop(self.forms.index(form))\n",
    "            return self.forms\n",
    "\n",
    "    def check_brackets(self, form):\n",
    "        \"\"\"\n",
    "        Checks if there are multiple variants of the form indicated by \"()\" and makes\n",
    "        two different forms from one form with brackets\n",
    "        \"\"\"\n",
    "        if \"(\" in form and \")\" in form:\n",
    "            i = form.index(\"(\")\n",
    "            j = form.index(\")\")\n",
    "            extraForm = form[:i] + form[i+1:j] + form[j+1:]\n",
    "            newForm = form[:i] + form[j+1:]\n",
    "            self.forms.append(extraForm)\n",
    "            self.forms.append(newForm)\n",
    "        elif \"[\" in form and \"]\" in form:\n",
    "            i = form.index(\"[\")\n",
    "            j = form.index(\"]\")\n",
    "            extraForm = form[:i] + form[i+1:j] + form[j+1:]\n",
    "            newForm = form[:i] + form[j+1:]\n",
    "            self.forms.append(extraForm)\n",
    "            self.forms.append(newForm)\n",
    "\n",
    "    def find_border(self):\n",
    "        for form in self.forms:\n",
    "            if len(form) >=2 and form[0] == \"-\":\n",
    "                self.border = form[1]\n",
    "                break\n",
    "        return self.border\n",
    "\n",
    "    def find_stem(self):\n",
    "        if len(self.forms) > 1:\n",
    "            for form in self.forms:\n",
    "                if len(form) > 1:\n",
    "                    if form[0] != '-' and self.border != '' and self.border in form:\n",
    "                        parts = form.split(self.border)\n",
    "                        self.stem = self.border.join(parts[:-1])\n",
    "                        break\n",
    "                    elif form[0] != '-' and self.border != '' and self.border in self.lemma:\n",
    "                        parts = self.lemma.split(self.border)\n",
    "                        self.stem = self.border.join(parts[:-1])\n",
    "                        break\n",
    "        else:\n",
    "            self.stem = self.lemma\n",
    "        return self.stem\n",
    "\n",
    "    def normalize(self, form):\n",
    "        \"\"\"Normalizes contracted forms\"\"\"\n",
    "        try:\n",
    "            if len(form) >= 2 and form[0] == \"-\":\n",
    "                if self.stem[-1] == 'i' and self.border in ['l', 'm', 'n', 'r']:\n",
    "                    form = self.stem[:-1] + form[1:]\n",
    "                    self.forms.append(form)\n",
    "                else:\n",
    "                    form = self.stem + form[1:]\n",
    "                    self.forms.append(form)\n",
    "        except IndexError:\n",
    "            pass\n",
    "\n",
    "    def make_lemmadict(self, words):\n",
    "        self.lemma = self.lemma.lower()\n",
    "        for form in self.forms:\n",
    "            form = form.lower()\n",
    "            if len(form) != 0 and form not in self.punctuation and form not in self.bad_forms:\n",
    "                if form not in words.keys():\n",
    "                    words[form] = (self.lemma,)\n",
    "                if self.lemma not in words.keys():\n",
    "                    words[self.lemma] = (self.lemma,)\n",
    "                else:\n",
    "                    if self.lemma not in words[form]:\n",
    "                        words[form] += (self.lemma,)\n",
    "        for k, v in words.items():\n",
    "            if len(v) == 0:\n",
    "                words[k] = k\n",
    "        words = {k:words[k] for k in words if len(k) != 0}\n",
    "        return words\n",
    "    \n",
    "    def make_dil(self, dil):\n",
    "        if len(self.defs) != 0:\n",
    "            self.lemma = self.lemma.lower()\n",
    "            self.lemma = re.sub(\"[\\[\\]\\(\\)?]+\", \"\", self.lemma)\n",
    "            self.forms = [re.sub(r\"[()[],:?]\", \"\", f) for f in self.forms]\n",
    "            filtered_forms = []\n",
    "            filtered_forms.append(self.lemma)\n",
    "            for form in self.forms:\n",
    "                form = form.lower()\n",
    "                if len(form) != 0 and form not in self.punctuation and form not in self.bad_forms:\n",
    "                    filtered_forms.append(form)\n",
    "            dil[self.lemma] = {'lemma': self.lemma, \n",
    "                               'forms': list(set(filtered_forms)),\n",
    "                               'defs': list(set(self.defs)),\n",
    "                               'first_trans_defs': self.first_trans_defs,\n",
    "                               'filtered_defs': self.filtered_defs,\n",
    "                              'trans': list(set(self.trans))}\n",
    "        return dil\n",
    "        \n",
    "\n",
    "def write_data(data, filename=\"parsed_dil.json\"):\n",
    "    with open(filename, \"w\", encoding = \"utf-8\") as f:\n",
    "        json.dump(data, f, sort_keys = True, ensure_ascii = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./dil/22696.txt\", 'r', encoding='utf-8') as f:\n",
    "    entry = Entry(f)\n",
    "    forms, lemma = entry.get_forms()\n",
    "    defs = entry.get_defs()\n",
    "    trans = entry.get_trans()\n",
    "    first_trans = entry.get_first_trans()\n",
    "    first_trans_defs = entry.get_first_trans_defs()\n",
    "    filtered_defs = entry.intersect_defs_trans()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['finds, gets',\n",
       " 'finds, meets with, discovers (in a place)',\n",
       " 'discovers',\n",
       " 'finds',\n",
       " 'gets, gains, obtains, procures',\n",
       " 'gets, induces (some one to do something) causes (something to be done)',\n",
       " 'meets with, experiences, undergoes',\n",
       " 'dies',\n",
       " 'gets (an opportunity of doing), is able (usually with vn. obj.; cf. c, d)',\n",
       " 'gets = spends, lives (through)',\n",
       " 'invents, devises',\n",
       " \"finds in oneself,' dares, presumes (late)\",\n",
       " 'imparts, communicates']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gets', 'finds']"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_trans_defs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gets', 'finds']"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_defs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['finds',\n",
       " 'gets',\n",
       " 'finds',\n",
       " 'meets with',\n",
       " 'discovers',\n",
       " 'discovers',\n",
       " 'finds',\n",
       " 'gets',\n",
       " 'gains',\n",
       " 'obtains',\n",
       " 'procures',\n",
       " 'gets',\n",
       " 'induces',\n",
       " 'causes',\n",
       " 'meets with',\n",
       " 'experiences',\n",
       " 'undergoes',\n",
       " 'dies',\n",
       " 'gets',\n",
       " 'is able',\n",
       " 'gets',\n",
       " 'spends',\n",
       " 'lives',\n",
       " 'invents',\n",
       " 'devises',\n",
       " 'finds in oneself',\n",
       " 'dares',\n",
       " 'presumes',\n",
       " 'imparts',\n",
       " 'communicates']"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "defs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing the eDIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43345/43345 [05:22<00:00, 134.31it/s]\n"
     ]
    }
   ],
   "source": [
    "dil = {}\n",
    "\n",
    "for root, dirs, files in os.walk(\"./dil\"):\n",
    "    for file in tqdm(files):\n",
    "        with open(os.path.join(root, file), 'r', encoding='utf-8') as f:\n",
    "            try:\n",
    "                entry = Entry(f)\n",
    "                forms, lemma = entry.get_forms()\n",
    "                defs = entry.get_defs()\n",
    "                trans = entry.get_trans()\n",
    "                first_trans = entry.get_first_trans()\n",
    "                first_trans_defs = entry.get_first_trans_defs()\n",
    "                filtered_defs = entry.intersect_defs_trans()\n",
    "                dil = entry.make_dil(dil)\n",
    "            except (AttributeError) as e:\n",
    "                print(\"%s: %s\" % (file, str(e)))\n",
    "                continue\n",
    "            \n",
    "    write_data(dil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lemma': 'catt',\n",
       " 'forms': ['cat', 'catt'],\n",
       " 'defs': ['cat-heads', 'cat', 'vulva', 'kitten'],\n",
       " 'first_trans_defs': ['cat'],\n",
       " 'filtered_defs': ['cat'],\n",
       " 'trans': ['cat-heads', 'cat', 'vulva (?)', 'kitten']}"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dil['catt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('parsed_dil.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(dil, f, ensure_ascii = False, sort_keys=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inverting translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_dil = {}\n",
    "for k, v in dil.items():\n",
    "    for d in v['filtered_defs']:\n",
    "        if d in inverted_dil:\n",
    "            inverted_dil[d].append(k)\n",
    "        else:\n",
    "            inverted_dil[d] = [k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['catt']"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inverted_dil['cat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('filtered_inverted_dil.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(inverted_dil, f, ensure_ascii = False, sort_keys=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving as a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "      <th>forms</th>\n",
       "      <th>defs</th>\n",
       "      <th>first_trans_defs</th>\n",
       "      <th>filtered_defs</th>\n",
       "      <th>trans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>immid</td>\n",
       "      <td>[imme, ime, immid]</td>\n",
       "      <td>[encloses, surrounds, makes a dam, fences]</td>\n",
       "      <td>[encloses, surrounds]</td>\n",
       "      <td>[encloses, surrounds]</td>\n",
       "      <td>[encloses, surrounds, fences (a field) ; makes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>seirgne</td>\n",
       "      <td>[seirgne, seirgni]</td>\n",
       "      <td>[shrivelled]</td>\n",
       "      <td>[shrivelled]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[state of being shrivelled (?)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>trácht</td>\n",
       "      <td>[trácht]</td>\n",
       "      <td>[breadth]</td>\n",
       "      <td>[breadth]</td>\n",
       "      <td>[breadth]</td>\n",
       "      <td>[breadth (?)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>doscaílte</td>\n",
       "      <td>[doscaílte, do-scóiltighe]</td>\n",
       "      <td>[loosen, impenetrability]</td>\n",
       "      <td>[loosen, impenetrability]</td>\n",
       "      <td>[impenetrability]</td>\n",
       "      <td>[impenetrability, state of being hard to loosen]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bairille</td>\n",
       "      <td>[bairille]</td>\n",
       "      <td>[barrel]</td>\n",
       "      <td>[barrel]</td>\n",
       "      <td>[barrel]</td>\n",
       "      <td>[barrel]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       lemma                       forms  \\\n",
       "0      immid          [imme, ime, immid]   \n",
       "1    seirgne          [seirgne, seirgni]   \n",
       "2     trácht                    [trácht]   \n",
       "3  doscaílte  [doscaílte, do-scóiltighe]   \n",
       "4   bairille                  [bairille]   \n",
       "\n",
       "                                         defs           first_trans_defs  \\\n",
       "0  [encloses, surrounds, makes a dam, fences]      [encloses, surrounds]   \n",
       "1                                [shrivelled]               [shrivelled]   \n",
       "2                                   [breadth]                  [breadth]   \n",
       "3                   [loosen, impenetrability]  [loosen, impenetrability]   \n",
       "4                                    [barrel]                   [barrel]   \n",
       "\n",
       "           filtered_defs                                              trans  \n",
       "0  [encloses, surrounds]  [encloses, surrounds, fences (a field) ; makes...  \n",
       "1                     []                    [state of being shrivelled (?)]  \n",
       "2              [breadth]                                      [breadth (?)]  \n",
       "3      [impenetrability]   [impenetrability, state of being hard to loosen]  \n",
       "4               [barrel]                                           [barrel]  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(dil.values())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"parced_dil.tsv\", sep=\"\\t\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting variation from headwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43345/43345 [03:22<00:00, 214.21it/s]\n"
     ]
    }
   ],
   "source": [
    "reg = re.compile(\",|\\(|\\)|\\[|\\]\")\n",
    "headers = []\n",
    "\n",
    "for root, dirs, files in os.walk(\"./dil\"):\n",
    "    for file in tqdm(files):\n",
    "        with open(os.path.join(root, file), 'r', encoding='utf-8') as f:\n",
    "            entry = Entry(f)\n",
    "            header = entry.get_header()\n",
    "            if reg.search(header):\n",
    "                headers.append(header)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = [i.replace('?', '') for i in headers]\n",
    "headers = [i.replace(':', '') for i in headers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_brackets(form, start, end):\n",
    "    i = form.index(start)\n",
    "    j = form.index(end)\n",
    "    form1 = form[:i] + form[i+1:j] + form[j+1:]\n",
    "    form2 = form[:i] + form[j+1:]\n",
    "    return [form1, form2]\n",
    "\n",
    "def clean_headers(headers):\n",
    "    cleaned_headers = []\n",
    "    for header in headers:\n",
    "        new_forms = []\n",
    "        forms = header.split(\",\")\n",
    "        for h in forms:\n",
    "            if '(' in h:\n",
    "                new_h = open_brackets(h.strip(), \"(\", \")\")\n",
    "            elif '[' in h:\n",
    "                new_h = open_brackets(h.strip(), \"[\", \"]\")\n",
    "            else:\n",
    "                new_h = [h.strip()]\n",
    "            new_forms += new_h\n",
    "        cleaned_headers.append(new_forms)\n",
    "    return cleaned_headers\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_headers = clean_headers(headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ellte', 'elltes'],\n",
       " ['foimmrimm', 'foimrimm'],\n",
       " ['toirche', 'toirchid'],\n",
       " ['breóaid', 'breóid'],\n",
       " ['rígdae', 'rígda', 'rída'],\n",
       " ['oíbne', 'oíbinne', ''],\n",
       " ['elefaint', 'elefint'],\n",
       " ['indsaigthech', 'innsaigech'],\n",
       " ['fáitbiud', 'fáitbe'],\n",
       " ['ind-asaig', 'in-asaig'],\n",
       " ['fríth', 'fríthe'],\n",
       " ['meild', 'meill'],\n",
       " ['smál', 'smól', 'smúal'],\n",
       " ['timthirecht', 'timpirecht'],\n",
       " ['éilmid', 'éilmigid'],\n",
       " ['greiss', 'greis'],\n",
       " ['anmothaigthige', 'anmothaige'],\n",
       " ['riclean', 'riclen'],\n",
       " ['léagad', 'léaga'],\n",
       " ['gnó', 'gnáe'],\n",
       " ['moned', 'monad'],\n",
       " ['in-ellaig', 'inellgither'],\n",
       " ['dimbág', 'dimbáig'],\n",
       " ['ullmachad', 'ullmugad'],\n",
       " ['ná', 'na'],\n",
       " ['dá n-', 'da n-'],\n",
       " ['íarngáesach', 'íargáesach'],\n",
       " ['ionnaid', 'innaid'],\n",
       " ['lúathugad', 'lúathad'],\n",
       " ['tobach', 'tabach'],\n",
       " ['metta', 'meta'],\n",
       " ['fuimiter', 'fumiterra'],\n",
       " ['íarcain', 'íarcáin'],\n",
       " ['teinntidecht', 'teintidecht'],\n",
       " ['plannta', 'planta'],\n",
       " ['ulchobchán', 'ulchobcán', 'ulchubchán', 'ulchubcán'],\n",
       " ['córaigid', 'cóirigid', 'cóirgid'],\n",
       " ['túaraim', 'túairim'],\n",
       " ['anaimm', 'anaim'],\n",
       " ['Sagsa', 'Sagsain'],\n",
       " ['tochraid', 'tachraid'],\n",
       " ['sochenéoil', 'sochenéuil'],\n",
       " ['ferthigsecht', 'fertigsecht'],\n",
       " ['druidid', 'druidim'],\n",
       " ['remmess', 'remmes'],\n",
       " ['forfeccaid', 'forfecaid'],\n",
       " ['fess', 'fes'],\n",
       " ['búacais', 'búaicis'],\n",
       " ['ruibe', 'roibe'],\n",
       " ['comsae', 'comsa']]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_headers[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"header_variation.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for i in cleaned_headers:\n",
    "        f.write(\"/\".join(i) + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
