{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import os, sys\n",
    "from urllib.request import urlopen\n",
    "\n",
    "def crawl_dil(path):\n",
    "    base = \"http://dil.ie/\"\n",
    "    os.makedirs(\"%s/dil\" % path, exist_ok=True)\n",
    "    for i in range(25854, 43346):\n",
    "        if i % 100 == 0:\n",
    "            print(\"Processing page \" + str(i))\n",
    "        link = base + str(i)\n",
    "        content = urlopen(link)\n",
    "        content = content.read()\n",
    "        text = content.decode(\"utf-8\")\n",
    "        with open(\"%s/dil/%s.txt\" % (path, str(i)), \"w\", encoding = \"utf-8\") as f:\n",
    "            f.write(text)\n",
    "\n",
    "class Entry():\n",
    "    headword = '<h3.*?>((\\?|\\d)\\s)*(.*?)</h3>'\n",
    "    formae = 'Forms:\\s*(.*?)</p>'\n",
    "    link = 'see.*?href=\\\".*?\\\">((\\?|\\d)\\s)*(.*?)</a>'\n",
    "    alph = 'abcdefghijklmnopqrstuvwxyzáóúíéṡḟōäïāūæēṅǽüöβīḯ'\n",
    "    bad_forms = [\"n\", \"m\", \"f\", \"a\", \"in\", \"is\", \"na\", \"con\", \"co\", \"ra\", \"ar\", \"ol\", \"bar\", \"for\", \"far\", \n",
    "                 \"an\", \"ro\", \"i\"]\n",
    "    punctuation = \" ?!,.:;†*—/\\-%'$~1234567890̆ \"\n",
    "    prefixes = ['co', 'con', 'for', 'do', 'at', 'as', 'ad', 'ní', 'ro', 'ra', 'a', 'ar', 'ath', 'aith',\n",
    "                'd', 'da', 'dan', 'der', 'derb', 'di', 'dob', 'dom', 'don', 'dot', 'é', 'fo', 'id', 'in',\n",
    "                'ind', 'imm', 'm', 'mí', 'n', 'nd', 'no', 'prím', 's', 't', 'to']\n",
    "\n",
    "\n",
    "    def __init__(self, file):\n",
    "        self.text = file.read()\n",
    "        self.forms = []\n",
    "        self.lemma = ''\n",
    "        self.border = ''\n",
    "        self.stem = ''\n",
    "\n",
    "    def get_forms(self):\n",
    "        res_headword = re.search(self.headword, self.text)\n",
    "        res_forms = re.search(self.formae, self.text)\n",
    "        res_link = re.search(self.link, self.text)\n",
    "        if res_headword:\n",
    "            if res_forms:\n",
    "                self.forms, self.lemma = self.process_forms(res_forms.group(1), res_headword.group(3))\n",
    "            elif res_link and '(' not in res_link.group(3):\n",
    "                self.forms, self.lemma = self.process_forms(res_headword.group(3), res_link.group(3))\n",
    "            else:\n",
    "                self.forms, self.lemma = self.process_forms(res_headword.group(3), res_headword.group(3))\n",
    "        return self.forms, self.lemma\n",
    "\n",
    "\n",
    "    def process_forms(self, forms, lemma):\n",
    "        \"\"\"\n",
    "        :param forms: string with forms\n",
    "        :param lemma: string with lemmas\n",
    "        \"\"\"\n",
    "        self.lemma = lemma.split(\",\")[0].strip(self.punctuation)\n",
    "        if '(?) ' in self.lemma:\n",
    "            self.lemma = self.lemma[self.lemma.index(\" \")+1:]\n",
    "        if self.lemma not in self.prefixes:\n",
    "            self.forms = forms.split(\",\") + lemma.split(\",\")\n",
    "            self.forms = [form.strip(\"1234567890?†* \") for form in self.forms]\n",
    "            self.forms = self.remove_junk()\n",
    "            self.forms = [form for form in self.forms if len(form) != 0]\n",
    "            for form in self.forms:\n",
    "                form = self.check_brackets(form)\n",
    "            self.border = self.find_border()\n",
    "            self.stem = self.find_stem()\n",
    "            for form in self.forms:\n",
    "                self.normalize(form)\n",
    "            self.forms = [form for form in self.forms if len(form) > 0 and form[0] != \"-\"]\n",
    "            self.forms = [form.strip(self.punctuation) for form in self.forms]\n",
    "        else:\n",
    "            pass\n",
    "        return self.forms, self.lemma\n",
    "\n",
    "    def remove_junk(self):\n",
    "            \"\"\"\n",
    "            :return: a list of forms without junk like zero-length forms and hardly restorable\n",
    "            variations in the middle of the form (\"-rrt(h)-\" etc.)\n",
    "            \"\"\"\n",
    "            for form in self.forms:\n",
    "                if len(form) != 0:\n",
    "                    if len(form) == 1 and form in self.punctuation:\n",
    "                        self.forms.pop(self.forms.index(form))\n",
    "                    elif form[0] == \"-\" and form[-1] == \"-\":\n",
    "                        self.forms.pop(self.forms.index(form))\n",
    "                    elif form[-1] == \".\" and len(form) <= 3:\n",
    "                        self.forms.pop(self.forms.index(form))\n",
    "                    elif form in self.bad_forms:\n",
    "                        self.forms.pop(self.forms.index(form))\n",
    "                    elif form[0] == '(' and form[-1] == ')':\n",
    "                        self.forms.pop(self.forms.index(form))\n",
    "                else:\n",
    "                    self.forms.pop(self.forms.index(form))\n",
    "            return self.forms\n",
    "\n",
    "    def check_brackets(self, form):\n",
    "        \"\"\"\n",
    "        Checks if there are multiple variants of the form indicated by \"()\" and makes\n",
    "        two different forms from one form with brackets\n",
    "        \"\"\"\n",
    "        if \"(\" in form and \")\" in form:\n",
    "            i = form.index(\"(\")\n",
    "            j = form.index(\")\")\n",
    "            extraForm = form[:i] + form[i+1:j] + form[j+1:]\n",
    "            newForm = form[:i] + form[j+1:]\n",
    "            self.forms.append(extraForm)\n",
    "            self.forms.append(newForm)\n",
    "        elif \"[\" in form and \"]\" in form:\n",
    "            i = form.index(\"[\")\n",
    "            j = form.index(\"]\")\n",
    "            extraForm = form[:i] + form[i+1:j] + form[j+1:]\n",
    "            newForm = form[:i] + form[j+1:]\n",
    "            self.forms.append(extraForm)\n",
    "            self.forms.append(newForm)\n",
    "\n",
    "    def find_border(self):\n",
    "        for form in self.forms:\n",
    "            if len(form) >=2 and form[0] == \"-\":\n",
    "                self.border = form[1]\n",
    "                break\n",
    "        return self.border\n",
    "\n",
    "    def find_stem(self):\n",
    "        if len(self.forms) > 1:\n",
    "            for form in self.forms:\n",
    "                if len(form) > 1:\n",
    "                    if form[0] != '-' and self.border != '' and self.border in form:\n",
    "                        parts = form.split(self.border)\n",
    "                        self.stem = self.border.join(parts[:-1])\n",
    "                        break\n",
    "                    elif form[0] != '-' and self.border != '' and self.border in self.lemma:\n",
    "                        parts = self.lemma.split(self.border)\n",
    "                        self.stem = self.border.join(parts[:-1])\n",
    "                        break\n",
    "        else:\n",
    "            self.stem = self.lemma\n",
    "        return self.stem\n",
    "\n",
    "    def normalize(self, form):\n",
    "        \"\"\"Normalizes contracted forms\"\"\"\n",
    "        try:\n",
    "            if len(form) >= 2 and form[0] == \"-\":\n",
    "                if self.stem[-1] == 'i' and self.border in ['l', 'm', 'n', 'r']:\n",
    "                    form = self.stem[:-1] + form[1:]\n",
    "                    self.forms.append(form)\n",
    "                else:\n",
    "                    form = self.stem + form[1:]\n",
    "                    self.forms.append(form)\n",
    "        except IndexError:\n",
    "            pass\n",
    "\n",
    "    def make_dict(self, words):\n",
    "        self.lemma = self.lemma.lower()\n",
    "        for form in self.forms:\n",
    "            form = form.lower()\n",
    "            if len(form) != 0 and form not in self.punctuation and form not in self.bad_forms and len(self.lemma) !=0:\n",
    "                if self.lemma not in words.keys():\n",
    "                    words[self.lemma] = set([form, lemma])\n",
    "                else:\n",
    "                    words[self.lemma].add(form)\n",
    "        return words\n",
    "        \n",
    "\n",
    "def write_data(words):\n",
    "    with open(\"./data/dil_lemmadict.json\", \"w\", encoding = \"utf-8\") as f:\n",
    "        json.dump(words, f, sort_keys = True, ensure_ascii = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/oksana/Dropbox/Библиотека/NUIG/Code/Embeddings'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing page 25900\n",
      "Processing page 26000\n",
      "Processing page 26100\n",
      "Processing page 26200\n",
      "Processing page 26300\n",
      "Processing page 26400\n",
      "Processing page 26500\n",
      "Processing page 26600\n",
      "Processing page 26700\n",
      "Processing page 26800\n",
      "Processing page 26900\n",
      "Processing page 27000\n",
      "Processing page 27100\n",
      "Processing page 27200\n",
      "Processing page 27300\n",
      "Processing page 27400\n",
      "Processing page 27500\n",
      "Processing page 27600\n",
      "Processing page 27700\n",
      "Processing page 27800\n",
      "Processing page 27900\n",
      "Processing page 28000\n",
      "Processing page 28100\n",
      "Processing page 28200\n",
      "Processing page 28300\n",
      "Processing page 28400\n",
      "Processing page 28500\n",
      "Processing page 28600\n",
      "Processing page 28700\n",
      "Processing page 28800\n",
      "Processing page 28900\n",
      "Processing page 29000\n",
      "Processing page 29100\n",
      "Processing page 29200\n",
      "Processing page 29300\n",
      "Processing page 29400\n",
      "Processing page 29500\n",
      "Processing page 29600\n",
      "Processing page 29700\n",
      "Processing page 29800\n",
      "Processing page 29900\n",
      "Processing page 30000\n",
      "Processing page 30100\n",
      "Processing page 30200\n",
      "Processing page 30300\n",
      "Processing page 30400\n",
      "Processing page 30500\n",
      "Processing page 30600\n",
      "Processing page 30700\n",
      "Processing page 30800\n",
      "Processing page 30900\n",
      "Processing page 31000\n",
      "Processing page 31100\n",
      "Processing page 31200\n",
      "Processing page 31300\n",
      "Processing page 31400\n",
      "Processing page 31500\n",
      "Processing page 31600\n",
      "Processing page 31700\n",
      "Processing page 31800\n",
      "Processing page 31900\n",
      "Processing page 32000\n",
      "Processing page 32100\n",
      "Processing page 32200\n",
      "Processing page 32300\n",
      "Processing page 32400\n",
      "Processing page 32500\n",
      "Processing page 32600\n",
      "Processing page 32700\n",
      "Processing page 32800\n",
      "Processing page 32900\n",
      "Processing page 33000\n",
      "Processing page 33100\n",
      "Processing page 33200\n",
      "Processing page 33300\n",
      "Processing page 33400\n",
      "Processing page 33500\n",
      "Processing page 33600\n",
      "Processing page 33700\n",
      "Processing page 33800\n",
      "Processing page 33900\n",
      "Processing page 34000\n",
      "Processing page 34100\n",
      "Processing page 34200\n",
      "Processing page 34300\n",
      "Processing page 34400\n",
      "Processing page 34500\n",
      "Processing page 34600\n",
      "Processing page 34700\n",
      "Processing page 34800\n",
      "Processing page 34900\n",
      "Processing page 35000\n",
      "Processing page 35100\n",
      "Processing page 35200\n",
      "Processing page 35300\n",
      "Processing page 35400\n",
      "Processing page 35500\n",
      "Processing page 35600\n",
      "Processing page 35700\n",
      "Processing page 35800\n",
      "Processing page 35900\n",
      "Processing page 36000\n",
      "Processing page 36100\n",
      "Processing page 36200\n",
      "Processing page 36300\n",
      "Processing page 36400\n",
      "Processing page 36500\n",
      "Processing page 36600\n",
      "Processing page 36700\n",
      "Processing page 36800\n",
      "Processing page 36900\n",
      "Processing page 37000\n",
      "Processing page 37100\n",
      "Processing page 37200\n",
      "Processing page 37300\n",
      "Processing page 37400\n",
      "Processing page 37500\n",
      "Processing page 37600\n",
      "Processing page 37700\n",
      "Processing page 37800\n",
      "Processing page 37900\n",
      "Processing page 38000\n",
      "Processing page 38100\n",
      "Processing page 38200\n",
      "Processing page 38300\n",
      "Processing page 38400\n",
      "Processing page 38500\n",
      "Processing page 38600\n",
      "Processing page 38700\n",
      "Processing page 38800\n",
      "Processing page 38900\n",
      "Processing page 39000\n",
      "Processing page 39100\n",
      "Processing page 39200\n",
      "Processing page 39300\n",
      "Processing page 39400\n",
      "Processing page 39500\n",
      "Processing page 39600\n",
      "Processing page 39700\n",
      "Processing page 39800\n",
      "Processing page 39900\n",
      "Processing page 40000\n",
      "Processing page 40100\n",
      "Processing page 40200\n",
      "Processing page 40300\n",
      "Processing page 40400\n",
      "Processing page 40500\n",
      "Processing page 40600\n",
      "Processing page 40700\n",
      "Processing page 40800\n",
      "Processing page 40900\n",
      "Processing page 41000\n",
      "Processing page 41100\n",
      "Processing page 41200\n",
      "Processing page 41300\n",
      "Processing page 41400\n",
      "Processing page 41500\n",
      "Processing page 41600\n",
      "Processing page 41700\n",
      "Processing page 41800\n",
      "Processing page 41900\n",
      "Processing page 42000\n",
      "Processing page 42100\n",
      "Processing page 42200\n",
      "Processing page 42300\n",
      "Processing page 42400\n",
      "Processing page 42500\n",
      "Processing page 42600\n",
      "Processing page 42700\n",
      "Processing page 42800\n",
      "Processing page 42900\n",
      "Processing page 43000\n",
      "Processing page 43100\n",
      "Processing page 43200\n",
      "Processing page 43300\n",
      "CPU times: user 20.8 s, sys: 15.3 s, total: 36 s\n",
      "Wall time: 4h 28min 28s\n"
     ]
    }
   ],
   "source": [
    "%time crawl_dil(os.getcwd() + \"/data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-e78fe4323d83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mwords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "words = {}\n",
    "\n",
    "for root, dirs, files in os.walk(os.getcwd() + \"/data/dil\"):\n",
    "    for name in files:\n",
    "        file = open(os.path.join(root, name), \"r\", encoding = \"utf-8\")\n",
    "        entry = Entry(file)\n",
    "        forms, lemma = entry.get_forms()\n",
    "        words = entry.make_dict(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in words.items():\n",
    "    words[k] = list(v)\n",
    "\n",
    "write_data(words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
